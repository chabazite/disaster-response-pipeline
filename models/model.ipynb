{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ai2318\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ai2318\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ai2318\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\ai2318\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download(['punkt', 'wordnet'])\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine(\n",
    "    'sqlite:///H:\\\\disaster-response-pipeline\\\\data\\\\disaster_record.db')\n",
    "\n",
    "#read table and separate X and Y features\n",
    "df = pd.read_sql_table('disaster_table', engine)\n",
    "\n",
    "X = df.iloc[:, 1].values\n",
    "y = df.iloc[:,5:40].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Weather update - a cold front from Cuba that could pass over Haiti',\n",
       "       'Is the Hurricane over or is it not over',\n",
       "       'Looking for someone but no name', ...,\n",
       "       \"Proshika, operating in Cox's Bazar municipality and 5 other unions, Ramu and Chokoria, assessment, 5 kg rice, 1,5 kg lentils to 700 families.\",\n",
       "       'Some 2,000 women protesting against the conduct of the elections were teargassed as they tried to converge on the local electoral commission offices in the southern oil city of Port Harcourt.',\n",
       "       'A radical shift in thinking came about as a result of this meeting, recognizing that HIV/AIDS is at the core of the humanitarian crisis and identifying the crisis itself as a function of the HIV/AIDS pandemic.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, validation_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "import re\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "stop_words = stopwords.words(\"english\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#Tokenize message\n",
    "def tokenize(text):\n",
    "    #remove punctuation\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\",\" \", text.lower())\n",
    "\n",
    "    #tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "\n",
    "    #lemmatize and remove stopwords\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "y_pred1 = pipeline.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               related       0.83      0.52      0.64      1125\n",
      "               request       0.00      0.00      0.00        32\n",
      "                 offer       0.76      0.70      0.73      2664\n",
      "           aid_related       0.62      0.09      0.16       483\n",
      "          medical_help       0.68      0.08      0.14       320\n",
      "      medical_products       0.77      0.06      0.11       175\n",
      "     search_and_rescue       0.00      0.00      0.00        98\n",
      "              security       0.71      0.05      0.09       203\n",
      "              military       0.00      0.00      0.00         0\n",
      "           child_alone       0.91      0.37      0.53       427\n",
      "                 water       0.83      0.59      0.69       691\n",
      "                  food       0.84      0.38      0.53       560\n",
      "               shelter       0.57      0.09      0.15        91\n",
      "              clothing       0.67      0.03      0.06       139\n",
      "                 money       1.00      0.01      0.03        73\n",
      "        missing_people       0.57      0.04      0.07       220\n",
      "              refugees       0.78      0.15      0.26       304\n",
      "                 death       0.62      0.04      0.07       890\n",
      "             other_aid       0.25      0.00      0.01       393\n",
      "infrastructure_related       0.90      0.10      0.17       273\n",
      "             transport       0.83      0.13      0.23       323\n",
      "             buildings       0.80      0.03      0.06       131\n",
      "           electricity       0.00      0.00      0.00        41\n",
      "                 tools       0.00      0.00      0.00        56\n",
      "             hospitals       0.00      0.00      0.00        23\n",
      "                 shops       0.00      0.00      0.00        74\n",
      "           aid_centers       0.00      0.00      0.00       275\n",
      "  other_infrastructure       0.86      0.71      0.78      1795\n",
      "       weather_related       0.90      0.51      0.65       488\n",
      "                floods       0.84      0.52      0.64       593\n",
      "                 storm       1.00      0.01      0.03        74\n",
      "                  fire       0.89      0.80      0.84       617\n",
      "            earthquake       1.00      0.07      0.13       132\n",
      "                  cold       0.50      0.02      0.03       337\n",
      "         other_weather       0.78      0.37      0.50      1282\n",
      "\n",
      "             micro avg       0.81      0.41      0.54     15402\n",
      "             macro avg       0.59      0.18      0.24     15402\n",
      "          weighted avg       0.74      0.41      0.48     15402\n",
      "           samples avg       0.41      0.24      0.29     15402\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ai2318\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ai2318\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ai2318\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\ai2318\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "labels = list(df.iloc[:,4:39].columns)\n",
    "\n",
    "print(classification_report(y_test, y_pred1, output_dict=False, target_names =labels))\n",
    "\n",
    "\n",
    "# for index, label in enumerate(labels):\n",
    "#     classification = classification_report(y_test[:,index], y_pred1[:,index]);\n",
    "#     print(label,\"\\n\",classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get parameters for pipeline\n",
    "pipeline.get_params().keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create gridsearch to improve params\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "    'clf__estimator__max_depth': [2,3,4,5,6],\n",
    "    'clf__estimator__min_samples_split': [2, 3,4,5],\n",
    "    'clf__estimator__n_estimators': [100, 200, 500]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.fit(X_train, y_train)\n",
    "y_pred = cv.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_score_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare original to HP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_HP = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_HP.fit(X_train, y_train,\n",
    "                clf__estimator__max_depth=,\n",
    "                clf__estimator__min_samples_split=,\n",
    "                clf__estimator__n_estimators=)\n",
    "y_pred_HP = pipeline_HP.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, label in enumerate(labels):\n",
    "    classification = classification_report(y_test[:,index], y_pred[:,index]);\n",
    "    print(label,\"\\n\",classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(df.iloc[:,4:40].columns)\n",
    "\n",
    "for index, label in enumerate(labels):\n",
    "    classification = classification_report(y_test[:,index], y_pred1[:,index]);\n",
    "    print(label,\"\\n\",classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kneighborclassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "pipeline_KN = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('kne', MultiOutputClassifier(KNeighborsClassifier()))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive-bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "pipeline_nb = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('nb', MultiOutputClassifier(MultinomialNB()))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost Classifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "pipeline_xg = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('xg', MultiOutputClassifier(XGBClassifier()))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Score\n",
    "pipeline_KN.fit(X_train, y_train)\n",
    "y_pred_KN = pipeline_KN.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_KN))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_nb.fit(X_train, y_train)\n",
    "y_pred_nb = pipeline_nb.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_xg.fit(X_train, y_train)\n",
    "y_pred_xg = pipeline_nb.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_xg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes doesn't have tuning capabilities like XGBoost does, so we will go with XG. We use the sampling avg for multi-label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'xg__estimator__min_child_weight': [0, 1, 5],\n",
    "    'xg__estimator__n_estimators': np.arange(100, 1000, 100),\n",
    "    'xg__estimator__learning_rate': [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "    'xg__estimator__gamma': [0, 1, 2],\n",
    "    'xg__estimator__max_depth': [1, 2, 4]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(pipeline_xg, param_grid=parameters,\n",
    "                  scoring='f1_macro', cv=2, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.fit(X_train, y_train)\n",
    "y_pred = cv.predict(X_test)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8f5863342bde2d50878861166c65e78d06ae2cfde69de5606dc6e5d3f968ba6"
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
